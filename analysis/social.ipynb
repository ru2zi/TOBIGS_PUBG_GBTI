{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.optimize import linprog\n",
    "import cvxpy as cp\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# pd.options.display.max_columns = None\n",
    "# pd.options.display.max_rows = None\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.cluster.hierarchy import linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('player_data.csv')\n",
    "\n",
    "# # 좌표를 분리하는 함수 정의\n",
    "# def split_coordinates(trajectory):\n",
    "#     if not trajectory or not isinstance(trajectory, str):  # 유효성 검사\n",
    "#         return []\n",
    "#     try:\n",
    "#         points = trajectory.split(\" -> \")\n",
    "#         coordinates = [tuple(map(float, point.strip(\"()\").split(\",\"))) for point in points]\n",
    "#         return coordinates\n",
    "#     except ValueError as e:\n",
    "#         # print(f\"Error processing trajectory: {trajectory}, Error: {e}\")\n",
    "#         return []\n",
    "\n",
    "# # 좌표를 리스트로 분리\n",
    "# coordinate_list = df[\"movement_routes\"].apply(split_coordinates)\n",
    "\n",
    "# # 최대 좌표 개수 계산\n",
    "# max_points = max(coordinate_list.apply(len))  # 최대 좌표 개수\n",
    "\n",
    "# # 새로운 컬럼 이름 생성 (x1, y1, z1, x2, y2, z2, ...)\n",
    "# column_names = []\n",
    "# for i in tqdm(range(1, max_points + 1)):\n",
    "#     column_names.extend([f\"x{i}\", f\"y{i}\", f\"z{i}\"])\n",
    "\n",
    "# # NaN을 방지하며 데이터를 펼침\n",
    "# expanded_df = pd.DataFrame(\n",
    "#     coordinate_list.tolist()\n",
    "# ).apply(\n",
    "#     lambda row: pd.Series([v for point in row if point for v in point]),\n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "# # 컬럼 이름 지정\n",
    "# expanded_df.columns = column_names[:expanded_df.shape[1]]\n",
    "\n",
    "# # 원본 데이터프레임과 병합\n",
    "# result = pd.concat([df, expanded_df], axis=1)\n",
    "\n",
    "# result.to_csv('new_player_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170756, 1128)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#row data와 다름 (위 주석 코드 실행한 csv)\n",
    "df = pd.read_csv('new_player_data.csv')\n",
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#첫 번째 시작 좌표가 None 값인 행 제거\n",
    "#탈퇴한 사람들 제거(피처 생성에 필요)\n",
    "def explorer_data_preprocessing(df, location_col='first_location_x', name_col='player_name'):\n",
    "    df = df[df[location_col] != 'None']\n",
    "    df = df[~df[name_col].isnull()]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170530, 1128)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = explorer_data_preprocessing(df)\n",
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Feature 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #거리 합산\n",
    "# df['total_distance'] = df['walk_distance']+df['ride_distance'] + df['swim_distance']\n",
    "# #분당 이동 거리의 합산\n",
    "# coordinate_columns = [col for col in df1.columns if col.startswith(('x', 'y', 'z'))]\n",
    "# coords = df[coordinate_columns].values.reshape(len(df1), -1, 3)\n",
    "# coords = np.nan_to_num(coords)\n",
    "# distances = np.sqrt(np.sum(np.diff(coords, axis=1)**2, axis=2))\n",
    "# df['total_movement_distance'] = distances.sum(axis=1)\n",
    "# # 플레이어별로 탐험한 맵의 개수 계산\n",
    "# map_diversity = df.groupby('player_name')['map_name'].nunique().reset_index()\n",
    "# map_diversity.columns = ['player_name', 'unique_maps']\n",
    "# df = df.merge(map_diversity[['player_name', 'unique_maps']], on='player_name', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_generation(df):  \n",
    "    # 거리 합산\n",
    "    df['total_distance'] = df['walk_distance'] + df['ride_distance'] + df['swim_distance']\n",
    "    \n",
    "    # 분당 이동 거리 합산 계산\n",
    "    coordinate_columns = [col for col in df.columns if col.startswith(('x', 'y', 'z'))]\n",
    "    coords = df[coordinate_columns].values.reshape(len(df), -1, 3)\n",
    "    coords = np.nan_to_num(coords)\n",
    "    distances = np.sqrt(np.sum(np.diff(coords, axis=1) ** 2, axis=2))\n",
    "    df['total_movement_distance'] = distances.sum(axis=1)\n",
    "    \n",
    "    # 플레이어별 탐험한 맵의 개수 계산\n",
    "    map_diversity = df.groupby('player_name')['map_name'].nunique().reset_index()\n",
    "    map_diversity.columns = ['player_name', 'unique_maps']\n",
    "    df = df.merge(map_diversity[['player_name', 'unique_maps']], on='player_name', how='left')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = feature_generation(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_distance             0\n",
       "total_movement_distance    0\n",
       "unique_maps                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#결측치 확인\n",
    "df[['total_distance', 'total_movement_distance', 'unique_maps']].isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Clustering(=Labeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_col = ['total_distance','total_movement_distance','unique_maps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    154771\n",
       "1     15759\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "\n",
    "# 클러스터링 수행\n",
    "df['cluster'] = kmeans.fit_predict(df[cluster_col])\n",
    "\n",
    "df['cluster'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[['total_distance','total_movement_distance','unique_maps','cluster']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_distance             0\n",
       "total_movement_distance    0\n",
       "unique_maps                0\n",
       "cluster                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df1[['total_distance', 'total_movement_distance', 'unique_maps']]\n",
    "y = df1['cluster']\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_x,train_y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1) DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier val acc 1.0\n",
      "DecisionTreeClassifier val f1_score 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier,ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "pred = dt.predict(X_val)\n",
    "print('DecisionTreeClassifier val acc',accuracy_score(y_val, pred))\n",
    "print('DecisionTreeClassifier val f1_score',f1_score(y_val, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier test acc 1.0\n",
      "DecisionTreeClassifier test f1_score 1.0\n"
     ]
    }
   ],
   "source": [
    "test_pred = dt.predict(test_x)\n",
    "print('DecisionTreeClassifier test acc',accuracy_score(test_y, test_pred))\n",
    "print('DecisionTreeClassifier test f1_score',f1_score(test_y, test_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2) ExtraTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier val acc 0.9993402968664101\n",
      "ExtraTreesClassifier val f1_score 0.9964328180737217\n"
     ]
    }
   ],
   "source": [
    "et = ExtraTreesClassifier()\n",
    "et.fit(X_train, y_train)\n",
    "pred = et.predict(X_val)\n",
    "print('ExtraTreesClassifier val acc',accuracy_score(y_val, pred))\n",
    "print('ExtraTreesClassifier val f1_score',f1_score(y_val, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier test acc 0.999530874332962\n",
      "ExtraTreesClassifier test f1_score 0.9974984365228267\n"
     ]
    }
   ],
   "source": [
    "test_pred = et.predict(test_x)\n",
    "print('ExtraTreesClassifier test acc',accuracy_score(test_y, test_pred))\n",
    "print('ExtraTreesClassifier test f1_score',f1_score(test_y, test_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3) RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier val acc 1.0\n",
      "RandomForestClassifier val f1_score 1.0\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "pred = rf.predict(X_val)\n",
    "print('RandomForestClassifier val acc',accuracy_score(y_val, pred))\n",
    "print('RandomForestClassifier val f1_score',f1_score(y_val, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier test acc 1.0\n",
      "RandomForestClassifier test f1_score 1.0\n"
     ]
    }
   ],
   "source": [
    "test_pred = rf.predict(test_x)\n",
    "print('RandomForestClassifier test acc',accuracy_score(test_y, test_pred))\n",
    "print('RandomForestClassifier test f1_score',f1_score(test_y, test_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4) AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier val acc 1.0\n",
      "AdaBoostClassifier val f1_score 1.0\n"
     ]
    }
   ],
   "source": [
    "adb = AdaBoostClassifier()\n",
    "adb.fit(X_train, y_train)\n",
    "pred = adb.predict(X_val)\n",
    "print('AdaBoostClassifier val acc',accuracy_score(y_val, pred))\n",
    "print('AdaBoostClassifier val f1_score',f1_score(y_val, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier test acc 1.0\n",
      "AdaBoostClassifier test f1_score 1.0\n"
     ]
    }
   ],
   "source": [
    "test_pred = adb.predict(test_x)\n",
    "print('AdaBoostClassifier test acc',accuracy_score(test_y, test_pred))\n",
    "print('AdaBoostClassifier test f1_score',f1_score(test_y, test_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5) GradientBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier val acc 1.0\n",
      "GradientBoostingClassifier val f1_score 1.0\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(X_train, y_train)\n",
    "pred = gb.predict(X_val)\n",
    "print('GradientBoostingClassifier val acc',accuracy_score(y_val, pred))\n",
    "print('GradientBoostingClassifier val f1_score',f1_score(y_val, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier test acc 1.0\n",
      "GradientBoostingClassifier test f1_score 1.0\n"
     ]
    }
   ],
   "source": [
    "test_pred = gb.predict(test_x)\n",
    "print('GradientBoostingClassifier test acc',accuracy_score(test_y, test_pred))\n",
    "print('GradientBoostingClassifier test f1_score',f1_score(test_y, test_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ExtraTree를 제외한 나머지 모델은 1.0  \n",
    "- 아무거나 쓰면 될 듯"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 최종 모델"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 랜덤포레스트 사용  \n",
    "- 과적합 방지 -> 튜닝 진행 x, 기본 모델로 선정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier val acc 1.0\n",
      "RandomForestClassifier val f1_score 1.0\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "pred = rf.predict(X_val)\n",
    "print('RandomForestClassifier val acc',accuracy_score(y_val, pred))\n",
    "print('RandomForestClassifier val f1_score',f1_score(y_val, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier test acc 1.0\n",
      "RandomForestClassifier test f1_score 1.0\n"
     ]
    }
   ],
   "source": [
    "test_pred = rf.predict(test_x)\n",
    "print('RandomForestClassifier test acc',accuracy_score(test_y, test_pred))\n",
    "print('RandomForestClassifier test f1_score',f1_score(test_y, test_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Model save to pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf_explorer_model.pkl']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(rf, 'rf_explorer_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = joblib.load('rf_explorer_model.pkl')\n",
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
